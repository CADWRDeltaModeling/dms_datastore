import nbformat as nbf

# Create a new notebook
nb = nbf.v4.new_notebook()

# Markdown cells
intro_markdown = """\
# Elevation Data Processing and Caching Example

This notebook demonstrates the use of a caching system designed to store and retrieve processed elevation data efficiently.
"""

import_markdown = """\
## Import Necessary Libraries

We import `pandas` for data manipulation and modules from `dms_datastore` which provide functionalities for reading time series data and caching mechanisms.
"""

function_markdown = """\
## Function Definition with Caching

Here we define a function `elev_data` that reads elevation data for a given station and variable, applies a cosine lanczos filter, and returns both the original and filtered data concatenated as a DataFrame. This function is decorated with `@cache_dataframe` to enable caching of its results.
"""

usage_markdown = """\
## Using the Caching System

We call the `elev_data` function with specific parameters to fetch data, which will be cached automatically due to our decorator. This step demonstrates fetching data for two different stations.
"""

saving_markdown = """\
## Saving Cache to CSV

After fetching and potentially caching the data, we proceed to save the cached data to CSV files. This ensures that we have a persistent copy of the cached data on disk.
"""

reload_markdown = """\
## Reloading and Verifying Cached Data

To ensure our caching system works correctly, we reload the data from the CSV files back into the cache and retrieve it again to verify its integrity.
"""

# Code cells
imports_code = """\
import pandas as pd
from dms_datastore.read_multi import *
from dms_datastore.caching import *
"""

function_code = """\
@cache_dataframe
def elev_data(station, variable, subloc):
    data = read_ts_repo(station, variable, subloc)
    filt = cosine_lanczos(data, '40H')
    return pd.concat({"mrz": data, "filt": filt}, axis=1)
"""

usage_code = """\
df1 = elev_data(station="mrz", variable="elev", subloc="upper")
df2 = elev_data(station="mal", variable="elev", subloc="upper")
"""

save_csv_code = """\
cache_to_csv()
"""

reload_code = """\
df1 = elev_data(station="mrz", variable="elev", subloc="upper")
cache_to_csv()
df1 = elev_data(station="mrz", variable="elev", subloc="upper")
load_cache_csv('elev_data.csv')
cache = CacheSingleton.get_instance()
print(cache[generate_cache_key(elev_data, station="mrz", variable="elev", subloc="upper")[0]])
"""

# Adding cells to the notebook
nb['cells'] = [
    nbf.v4.new_markdown_cell(intro_markdown),
    nbf.v4.new_markdown_cell(import_markdown),
    nbf.v4.new_code_cell(imports_code),
    nbf.v4.new_markdown_cell(function_markdown),
    nbf.v4.new_code_cell(function_code),
    nbf.v4.new_markdown_cell(usage_markdown),
    nbf.v4.new_code_cell(usage_code),
    nbf.v4.new_markdown_cell(saving_markdown),
    nbf.v4.new_code_cell(save_csv_code),
    nbf.v4.new_markdown_cell(reload_markdown),
    nbf.v4.new_code_cell(reload_code),
]

# Write the notebook to a new file
nbf.write(nb, '/mnt/data/Elevation_Data_Caching_Example.ipynb')

'/mnt/data/Elevation_Data_Caching_Example.ipynb'
